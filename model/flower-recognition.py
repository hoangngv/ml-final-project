# -*- coding: utf-8 -*-
"""ml-flower-recognition

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-pAnn9XfR6zneBVfMrgZZYo1B85WdVrq
"""

import numpy as np
import os
import time
# from vgg16 import VGG16
from keras.preprocessing import image
from keras.applications.imagenet_utils import preprocess_input
import numpy as np
import os
import time
from keras.layers import AveragePooling2D, GlobalAveragePooling2D
import matplotlib.pyplot as plt
from keras.models import Model
from keras.optimizers import Adam
from keras.applications import ResNet50
from keras.utils.data_utils import Sequence
from keras.layers import Dense, Activation, Flatten, Dropout, merge, Input
from albumentations import (
    Compose, HorizontalFlip, Rotate, CLAHE, HueSaturationValue,
    RandomBrightness, RandomContrast, RandomGamma, JpegCompression,RGBShift,
    ToFloat, ShiftScaleRotate
)
from keras.models import Model
from keras.utils import np_utils

!unzip -q "/content/drive/My Drive/514569_948457_bundle_archive.zip"
list_flower = ["lotus", "daisy", "rose", "sunflower", "common dandelion", "common tulip", "camellia", "anthurium", "iris", "morning glory"]

from google.colab import drive
drive.mount('/content/drive')

# Loading the training data
data_path = "/content/jpeg-224x224/train"
img_data_list_lotus_train=[]
img_data_list_rose_train=[]
img_data_list_sunflower_train=[]
img_data_list_daisy_train=[]
img_data_list_common_dandelion_train=[]
img_data_list_common_tulip_train=[]
img_data_list_camellia_train=[]
img_data_list_anthurium_train=[]
img_data_list_iris_train=[]
img_data_list_morning_glory_train = []
for dataset in list_flower:
    folder_path = os.listdir(data_path+'/'+ dataset)
    for im in folder_path:
      img_path = data_path + '/'+ dataset + '/' + im
      img = image.load_img(img_path, target_size=(224, 224))
      x = image.img_to_array(img)
      x = np.expand_dims(x, axis=0)
      x = preprocess_input(x)
      x = x/255
      if dataset == 'lotus':
        img_data_list_lotus_train.append(x)
      elif dataset == 'daisy':
        img_data_list_daisy_train.append(x)
      elif dataset == 'rose':
        img_data_list_rose_train.append(x)
      elif dataset == 'sunflower':
        img_data_list_sunflower_train.append(x)   
      elif dataset == 'common dandelion':
        img_data_list_common_dandelion_train.append(x)
      elif dataset == 'common tulip':
        img_data_list_common_tulip_train.append(x)
      elif dataset == 'camellia':
        img_data_list_camellia_train.append(x)
      elif dataset == 'anthurium':
        img_data_list_anthurium_train.append(x)
      elif dataset == 'iris':
        img_data_list_iris_train.append(x)
      else:
        img_data_list_morning_glory_train.append(x)

img_data_train = np.concatenate((np.array(img_data_list_lotus_train), np.array(img_data_list_daisy_train), np.array(img_data_list_rose_train), np.array(img_data_list_sunflower_train), np.array(img_data_list_common_dandelion_train),np.array(img_data_list_common_tulip_train), np.array(img_data_list_camellia_train), np.array(img_data_list_anthurium_train), np.array(img_data_list_iris_train), np.array(img_data_list_morning_glory_train)))

# Loading the val data
data_path = "/content/jpeg-224x224/val"
img_data_list_lotus_train=[]
img_data_list_rose_train=[]
img_data_list_sunflower_train=[]
img_data_list_daisy_train=[]
img_data_list_common_dandelion_train=[]
img_data_list_common_tulip_train=[]
img_data_list_camellia_train=[]
img_data_list_anthurium_train=[]
img_data_list_iris_train=[]
img_data_list_morning_glory_train = []
for dataset in list_flower:
    folder_path = os.listdir(data_path+'/'+ dataset)
    for im in folder_path:
      img_path = data_path + '/'+ dataset + '/' + im
      img = image.load_img(img_path, target_size=(224, 224))
      x = image.img_to_array(img)
      x = np.expand_dims(x, axis=0)
      x = preprocess_input(x)
      x = x/255
      if dataset == 'lotus':
        img_data_list_lotus_train.append(x)
      elif dataset == 'daisy':
        img_data_list_daisy_train.append(x)
      elif dataset == 'rose':
        img_data_list_rose_train.append(x)
      elif dataset == 'sunflower':
        img_data_list_sunflower_train.append(x)   
      elif dataset == 'common dandelion':
        img_data_list_common_dandelion_train.append(x)
      elif dataset == 'common tulip':
        img_data_list_common_tulip_train.append(x)
      elif dataset == 'camellia':
        img_data_list_camellia_train.append(x)
      elif dataset == 'anthurium':
        img_data_list_anthurium_train.append(x)
      elif dataset == 'iris':
        img_data_list_iris_train.append(x)
      else:
        img_data_list_morning_glory_train.append(x)

img_data_val = np.concatenate((np.array(img_data_list_lotus_train), np.array(img_data_list_daisy_train), np.array(img_data_list_rose_train), np.array(img_data_list_sunflower_train), np.array(img_data_list_common_dandelion_train),np.array(img_data_list_common_tulip_train), np.array(img_data_list_camellia_train), np.array(img_data_list_anthurium_train), np.array(img_data_list_iris_train), np.array(img_data_list_morning_glory_train)))

img_data_train = np.rollaxis(img_data_train,1,0)
img_data_train = img_data_train[0]
img_data_val = np.rollaxis(img_data_val,1,0)
img_data_val = img_data_val[0]

X_train = img_data_train
X_val = img_data_val

num_classes = 10
# num_of_samples = img_data.shape[0]
y_train = np.ones((3767,),dtype='int64')
y_val = np.ones((1098,),dtype='int64')
y_train[0:139]=0
y_train[139:561]=1
y_train[561:1021]=2
y_train[1021:1481]=3
y_train[1481:2044]=4
y_train[2044:2434]=5
y_train[2434:2561]=6
y_train[2561:2679]=7
y_train[2679:3461]=8
y_train[3461:]=9

y_val[0:41]=0
y_val[41:164]=1
y_val[164:298]=2
y_val[298:432]=3
y_val[432:596]=4
y_val[596:710]=5
y_val[710:747]=6
y_val[747:781]=7
y_val[781:1009]=8
y_val[1009:]=9

y_train = np_utils.to_categorical(y_train, num_classes)
y_val = np_utils.to_categorical(y_val, num_classes)

from keras.applications import VGG16
image_input = Input(shape=(224, 224, 3))

model = VGG16(input_tensor=image_input, include_top=True,weights='imagenet')

model.summary()

last_layer = model.get_layer('block5_pool').output
x= Flatten(name='flatten')(last_layer)
x = Dense(512, activation='relu', name='fc2')(x)
x = Dropout(0.5)(x)
out = Dense(10, activation='softmax', name='output')(x)
custom_vgg_model2 = Model(image_input, out)
#custom_vgg_model2.summary()

# freeze all the layers except the dense layers
for layer in custom_vgg_model2.layers[0:]:
	layer.trainable = True
custom_vgg_model2.layers[0].trainable = False
custom_vgg_model2.summary()

from keras.preprocessing.image import ImageDataGenerator
datagen = ImageDataGenerator(
        rotation_range=20,
        width_shift_range=0.1,
        height_shift_range=0.1,
        shear_range=0.2,
        zoom_range=0.1,
        horizontal_flip=True)

datagen.fit(X_train)

import matplotlib.pyplot as plt
for x_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):
    # Show the first 9 images
    for i in range(0, 9):
        plt.subplot(330 + 1 + i)
        plt.imshow(x_batch[i].reshape(224, 224, 3))
    # show the plot
    plt.show()
    break

from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler
from keras.optimizers import Adam
opt = Adam(lr=1e-4)
custom_vgg_model2.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])
checkpoint = ModelCheckpoint("vgg16_flower.h5", monitor='val_loss', verbose=1, save_best_only=True, mode='min')
#	t = now()

# hist = custom_resnet_model.fit(X_train, y_train, batch_size=32, epochs=20, verbose=1, validation_data=(X_val, y_val), callbacks=[checkpoint,early])
hist = custom_vgg_model2.fit_generator(
        datagen.flow(X_train, y_train, batch_size=32),
        steps_per_epoch=X_train.shape[0]//32,
        epochs=20,
        validation_data=(X_val, y_val),
        callbacks=[checkpoint])