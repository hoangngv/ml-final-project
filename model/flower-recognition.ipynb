{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml-flower-recognition",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWJh6bZbx8PD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "# from vgg16 import VGG16\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from keras.layers import AveragePooling2D, GlobalAveragePooling2D\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.applications import ResNet50\n",
        "from keras.utils.data_utils import Sequence\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, merge, Input\n",
        "from albumentations import (\n",
        "    Compose, HorizontalFlip, Rotate, CLAHE, HueSaturationValue,\n",
        "    RandomBrightness, RandomContrast, RandomGamma, JpegCompression,RGBShift,\n",
        "    ToFloat, ShiftScaleRotate\n",
        ")\n",
        "from keras.models import Model\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGMtsVw-5Orf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q \"/content/drive/My Drive/514569_948457_bundle_archive.zip\"\n",
        "list_flower = [\"lotus\", \"daisy\", \"rose\", \"sunflower\", \"common dandelion\", \"common tulip\", \"camellia\", \"anthurium\", \"iris\", \"morning glory\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv2DCwH9IOZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u232CPIwDF8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading the training data\n",
        "data_path = \"/content/jpeg-224x224/train\"\n",
        "img_data_list_lotus_train=[]\n",
        "img_data_list_rose_train=[]\n",
        "img_data_list_sunflower_train=[]\n",
        "img_data_list_daisy_train=[]\n",
        "img_data_list_common_dandelion_train=[]\n",
        "img_data_list_common_tulip_train=[]\n",
        "img_data_list_camellia_train=[]\n",
        "img_data_list_anthurium_train=[]\n",
        "img_data_list_iris_train=[]\n",
        "img_data_list_morning_glory_train = []\n",
        "for dataset in list_flower:\n",
        "    folder_path = os.listdir(data_path+'/'+ dataset)\n",
        "    for im in folder_path:\n",
        "      img_path = data_path + '/'+ dataset + '/' + im\n",
        "      img = image.load_img(img_path, target_size=(224, 224))\n",
        "      x = image.img_to_array(img)\n",
        "      x = np.expand_dims(x, axis=0)\n",
        "      x = preprocess_input(x)\n",
        "      x = x/255\n",
        "      if dataset == 'lotus':\n",
        "        img_data_list_lotus_train.append(x)\n",
        "      elif dataset == 'daisy':\n",
        "        img_data_list_daisy_train.append(x)\n",
        "      elif dataset == 'rose':\n",
        "        img_data_list_rose_train.append(x)\n",
        "      elif dataset == 'sunflower':\n",
        "        img_data_list_sunflower_train.append(x)   \n",
        "      elif dataset == 'common dandelion':\n",
        "        img_data_list_common_dandelion_train.append(x)\n",
        "      elif dataset == 'common tulip':\n",
        "        img_data_list_common_tulip_train.append(x)\n",
        "      elif dataset == 'camellia':\n",
        "        img_data_list_camellia_train.append(x)\n",
        "      elif dataset == 'anthurium':\n",
        "        img_data_list_anthurium_train.append(x)\n",
        "      elif dataset == 'iris':\n",
        "        img_data_list_iris_train.append(x)\n",
        "      else:\n",
        "        img_data_list_morning_glory_train.append(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgMPBWlkDJbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_data_train = np.concatenate((np.array(img_data_list_lotus_train), np.array(img_data_list_daisy_train), np.array(img_data_list_rose_train), np.array(img_data_list_sunflower_train), np.array(img_data_list_common_dandelion_train),np.array(img_data_list_common_tulip_train), np.array(img_data_list_camellia_train), np.array(img_data_list_anthurium_train), np.array(img_data_list_iris_train), np.array(img_data_list_morning_glory_train)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcmDsj6u5O0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading the val data\n",
        "data_path = \"/content/jpeg-224x224/val\"\n",
        "img_data_list_lotus_train=[]\n",
        "img_data_list_rose_train=[]\n",
        "img_data_list_sunflower_train=[]\n",
        "img_data_list_daisy_train=[]\n",
        "img_data_list_common_dandelion_train=[]\n",
        "img_data_list_common_tulip_train=[]\n",
        "img_data_list_camellia_train=[]\n",
        "img_data_list_anthurium_train=[]\n",
        "img_data_list_iris_train=[]\n",
        "img_data_list_morning_glory_train = []\n",
        "for dataset in list_flower:\n",
        "    folder_path = os.listdir(data_path+'/'+ dataset)\n",
        "    for im in folder_path:\n",
        "      img_path = data_path + '/'+ dataset + '/' + im\n",
        "      img = image.load_img(img_path, target_size=(224, 224))\n",
        "      x = image.img_to_array(img)\n",
        "      x = np.expand_dims(x, axis=0)\n",
        "      x = preprocess_input(x)\n",
        "      x = x/255\n",
        "      if dataset == 'lotus':\n",
        "        img_data_list_lotus_train.append(x)\n",
        "      elif dataset == 'daisy':\n",
        "        img_data_list_daisy_train.append(x)\n",
        "      elif dataset == 'rose':\n",
        "        img_data_list_rose_train.append(x)\n",
        "      elif dataset == 'sunflower':\n",
        "        img_data_list_sunflower_train.append(x)   \n",
        "      elif dataset == 'common dandelion':\n",
        "        img_data_list_common_dandelion_train.append(x)\n",
        "      elif dataset == 'common tulip':\n",
        "        img_data_list_common_tulip_train.append(x)\n",
        "      elif dataset == 'camellia':\n",
        "        img_data_list_camellia_train.append(x)\n",
        "      elif dataset == 'anthurium':\n",
        "        img_data_list_anthurium_train.append(x)\n",
        "      elif dataset == 'iris':\n",
        "        img_data_list_iris_train.append(x)\n",
        "      else:\n",
        "        img_data_list_morning_glory_train.append(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t47yIh-e6LU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_data_val = np.concatenate((np.array(img_data_list_lotus_train), np.array(img_data_list_daisy_train), np.array(img_data_list_rose_train), np.array(img_data_list_sunflower_train), np.array(img_data_list_common_dandelion_train),np.array(img_data_list_common_tulip_train), np.array(img_data_list_camellia_train), np.array(img_data_list_anthurium_train), np.array(img_data_list_iris_train), np.array(img_data_list_morning_glory_train)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-k2SmQu6vDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_data_train = np.rollaxis(img_data_train,1,0)\n",
        "img_data_train = img_data_train[0]\n",
        "img_data_val = np.rollaxis(img_data_val,1,0)\n",
        "img_data_val = img_data_val[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz8wIVru6vKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = img_data_train\n",
        "X_val = img_data_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv4vueVs6vQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 10\n",
        "# num_of_samples = img_data.shape[0]\n",
        "y_train = np.ones((3767,),dtype='int64')\n",
        "y_val = np.ones((1098,),dtype='int64')\n",
        "y_train[0:139]=0\n",
        "y_train[139:561]=1\n",
        "y_train[561:1021]=2\n",
        "y_train[1021:1481]=3\n",
        "y_train[1481:2044]=4\n",
        "y_train[2044:2434]=5\n",
        "y_train[2434:2561]=6\n",
        "y_train[2561:2679]=7\n",
        "y_train[2679:3461]=8\n",
        "y_train[3461:]=9\n",
        "\n",
        "y_val[0:41]=0\n",
        "y_val[41:164]=1\n",
        "y_val[164:298]=2\n",
        "y_val[298:432]=3\n",
        "y_val[432:596]=4\n",
        "y_val[596:710]=5\n",
        "y_val[710:747]=6\n",
        "y_val[747:781]=7\n",
        "y_val[781:1009]=8\n",
        "y_val[1009:]=9\n",
        "\n",
        "y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "y_val = np_utils.to_categorical(y_val, num_classes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG2Vl36n62b-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications import VGG16\n",
        "image_input = Input(shape=(224, 224, 3))\n",
        "\n",
        "model = VGG16(input_tensor=image_input, include_top=True,weights='imagenet')\n",
        "\n",
        "model.summary()\n",
        "\n",
        "last_layer = model.get_layer('block5_pool').output\n",
        "x= Flatten(name='flatten')(last_layer)\n",
        "x = Dense(512, activation='relu', name='fc2')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "out = Dense(10, activation='softmax', name='output')(x)\n",
        "custom_vgg_model2 = Model(image_input, out)\n",
        "#custom_vgg_model2.summary()\n",
        "\n",
        "# freeze all the layers except the dense layers\n",
        "for layer in custom_vgg_model2.layers[0:]:\n",
        "\tlayer.trainable = True\n",
        "custom_vgg_model2.layers[0].trainable = False\n",
        "custom_vgg_model2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4qzNLRo65b3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.1,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "datagen.fit(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYo_JXkJ65h6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "for x_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n",
        "    # Show the first 9 images\n",
        "    for i in range(0, 9):\n",
        "        plt.subplot(330 + 1 + i)\n",
        "        plt.imshow(x_batch[i].reshape(224, 224, 3))\n",
        "    # show the plot\n",
        "    plt.show()\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3nI2A7h7Yc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
        "from keras.optimizers import Adam\n",
        "opt = Adam(lr=1e-4)\n",
        "custom_vgg_model2.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "checkpoint = ModelCheckpoint(\"vgg16_flower.h5\", monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "#\tt = now()\n",
        "\n",
        "# hist = custom_resnet_model.fit(X_train, y_train, batch_size=32, epochs=20, verbose=1, validation_data=(X_val, y_val), callbacks=[checkpoint,early])\n",
        "hist = custom_vgg_model2.fit_generator(\n",
        "        datagen.flow(X_train, y_train, batch_size=32),\n",
        "        steps_per_epoch=X_train.shape[0]//32,\n",
        "        epochs=20,\n",
        "        validation_data=(X_val, y_val),\n",
        "        callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}